{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.datasets import load_dataset, available_datasets\n",
    "from src.models import available_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f-mnist']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this example we'll use the training data to build and deploy the initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-10 21:11:12,162 - fetch - INFO - Ungzipping train-images-idx3-ubyte\n",
      "2018-10-10 21:11:12,588 - fetch - INFO - Ungzipping train-labels-idx1-ubyte\n",
      "2018-10-10 21:11:12,590 - fetch - INFO - Ungzipping t10k-images-idx3-ubyte\n",
      "2018-10-10 21:11:12,669 - fetch - INFO - Ungzipping t10k-labels-idx1-ubyte\n",
      "2018-10-10 21:11:12,671 - fetch - INFO - Copying f-mnist.license\n",
      "2018-10-10 21:11:12,672 - fetch - INFO - Copying f-mnist.readme\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset('f-mnist', kind='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an algorithm\n",
    "\n",
    "`make train`\n",
    "\n",
    "We're going to build an visulization tool for our stylists to use. Let's use the UMAP dimension reduction algorithm for this.\n",
    "\n",
    "https://umap-learn.readthedocs.io/en/latest/\n",
    "\n",
    "We can pip install umap via:\n",
    "\n",
    "`pip install umap-learn`\n",
    "\n",
    "Time to show off your new reproducible environment skills!\n",
    "\n",
    "Add `umap-learn` under your pip requirements in the `environment.yml` and run `make requirements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want a 2 dimensional visualization\n",
    "model = UMAP(n_components=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 6.5 s, total: 2min 16s\n",
      "Wall time: 1min 58s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UMAP(a=None, angular_rp_forest=False, b=None, init='spectral',\n",
       "   learning_rate=1.0, local_connectivity=1.0, metric='euclidean',\n",
       "   metric_kwds=None, min_dist=0.1, n_components=2, n_epochs=None,\n",
       "   n_neighbors=15, negative_sample_rate=5, random_state=42,\n",
       "   repulsion_strength=1.0, set_op_mix_ratio=1.0, spread=1.0,\n",
       "   target_metric='categorical', target_metric_kwds=None,\n",
       "   target_n_neighbors=-1, target_weight=0.5, transform_queue_size=4.0,\n",
       "   transform_seed=42, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(ds.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that UMAP is a BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, BaseEstimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Add UMAP to the available_algorithms and add an entry to model_list.json for training UMAP on f-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7c0d9c43d56d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;34m'umap'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_algorithms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 'umap' in available_algorithms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 -m src.models.train_model model_list.json\n",
      "/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2018-10-10 21:31:01,223 - train_model - INFO - Building models from model_list.json\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ava00125/src/devel/bus_number/src/models/train_model.py\", line 112, in <module>\n",
      "    main()\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 764, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 717, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 956, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 555, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/ava00125/src/devel/bus_number/src/models/train_model.py\", line 71, in main\n",
      "    assert ds_name in dataset_list, f'Unknown Dataset: {ds_name}'\n",
      "AssertionError: Unknown Dataset: lvq-pak\n",
      "make: *** [train] Error 1\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use it to predict\n",
    "`make predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 3, 7, 2, 1, 5, 2, 5, 2, 1, 8, 4, 0, 4, 2, 3, 7, 8, 8, 4, 3,\n",
       "       9, 7, 1, 6, 3, 5, 6, 3, 4, 9, 1, 4, 4, 6, 9, 4, 7, 6, 6, 9, 1, 3,\n",
       "       6, 1, 3, 0, 6, 5, 5, 1, 9, 5, 6, 0, 2, 0, 0, 1, 0, 4, 5, 2, 4, 5,\n",
       "       7, 0, 7, 5, 9, 5, 5, 4, 7, 0, 4, 5, 5, 9, 9, 0, 2, 3, 8, 0, 6, 4,\n",
       "       4, 9, 1, 2, 8, 3, 5, 2, 9, 4, 4, 4, 4, 3, 5, 3, 1, 3, 5, 9, 4, 2,\n",
       "       7, 7, 4, 4, 1, 9, 2, 7, 8, 7, 2, 6, 9, 4, 0, 7, 2, 7, 5, 8, 7, 5,\n",
       "       7, 9, 0, 6, 6, 4, 2, 8, 0, 9, 4, 6, 9, 9, 6, 9, 0, 5, 5, 6, 6, 0,\n",
       "       6, 4, 2, 9, 3, 8, 7, 2, 9, 0, 4, 5, 3, 6, 5, 8, 9, 8, 4, 2, 1, 3,\n",
       "       7, 3, 2, 2, 3, 9, 8, 0, 3, 2, 2, 5, 6, 9, 9, 4, 1, 2, 4, 2, 3, 6,\n",
       "       4, 8, 5, 9, 5, 7, 8, 9, 4, 8, 1, 5, 4, 4, 9, 6, 1, 8, 6, 0, 4, 5,\n",
       "       2, 7, 1, 6, 4, 5, 6, 0, 3, 2, 3, 6, 7, 1, 9, 1, 4, 7, 6, 5, 8, 5,\n",
       "       5, 1, 5, 2, 8, 8, 9, 8, 7, 6, 2, 2, 2, 3, 4, 8, 8, 3, 6, 0, 8, 7,\n",
       "       7, 0, 1, 0, 4, 5, 8, 5, 3, 6, 0, 4, 1, 0, 0, 3, 6, 5, 9, 7, 3, 5,\n",
       "       5, 9, 9, 8, 5, 3, 3, 2, 0, 5, 8, 3, 4, 0, 2, 4, 6, 4, 3, 4, 5, 0,\n",
       "       5, 2, 1, 3, 1, 4, 1, 1, 7, 0, 1, 5, 2, 1, 2, 8, 7, 0, 6, 4, 8, 8,\n",
       "       5, 1, 8, 4, 5, 8, 7, 9, 8, 8, 0, 6, 2, 0, 7, 9, 1, 9, 5, 2, 7, 7,\n",
       "       1, 8, 7, 4, 3, 8, 3, 5, 6, 0, 0, 3, 0, 5, 0, 0, 4, 1, 2, 3, 8, 5,\n",
       "       8, 6, 3, 4, 8, 8, 4, 2, 3, 8, 9, 8, 8, 5, 0, 6, 3, 3, 7, 1, 6, 4,\n",
       "       8, 2, 1, 8, 6, 4, 7, 4, 8, 3, 4, 0, 5, 1, 9, 4, 5, 7, 6, 3, 7, 0,\n",
       "       5, 9, 7, 5, 9, 7, 4, 2, 2, 9, 0, 7, 5, 8, 3, 6, 3, 9, 6, 9, 5, 0,\n",
       "       1, 5, 5, 8, 3, 3, 6, 2, 6, 5, 7, 2, 0, 8, 7, 3, 7, 0, 2, 2, 3, 5,\n",
       "       8, 7, 3, 6, 5, 9, 9, 2, 1, 6, 3, 0, 7, 1, 1, 9, 6, 1, 8, 0, 0, 2,\n",
       "       9, 8, 9, 9, 2, 7, 3, 1, 3, 5, 4, 6, 8, 2, 1, 8, 8, 7, 6, 9, 2, 0,\n",
       "       4, 9, 3, 8, 7, 1, 3, 1, 9, 1, 8, 5, 1, 7, 0, 0, 2, 2, 6, 9, 4, 8,\n",
       "       9, 0, 6, 7, 7, 9, 5, 4, 7, 0, 7, 6, 8, 7, 1, 4, 6, 2, 8, 7, 5, 9,\n",
       "       0, 3, 9, 6, 6, 1, 9, 8, 2, 9, 8, 9, 7, 4, 8, 5, 5, 9, 7, 7, 6, 8,\n",
       "       1, 3, 5, 7, 9, 5, 5, 2, 1, 1, 2, 2, 4, 9, 7, 5, 8, 8, 9, 4, 9, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_test = model.predict(X_test);\n",
    "p_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the quality of the prediction\n",
    "`make analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9292929292929293"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9292929292929293"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, p_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: \n",
    "* automate the basic workflow\n",
    "* compare a bunch of algorithms for our Swedish Chef paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add our algorithm to available_algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import available_algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are currently no available algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an algorithm, add  a key:value pair to the dict `_ALGORITHMS` in `src/models/algorithms.py`.\n",
    "\n",
    "For example, add\n",
    "```\n",
    "'linearSVC': LinearSVC()\n",
    "```\n",
    "to the `_ALGORITHMS` dict, and add\n",
    "```\n",
    "from sklearn.svm import LinearSVC\n",
    "```\n",
    "to the top of the file.\n",
    "\n",
    "Also, add `linearSVC` to the docstring of `available_algorithms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linearSVC']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "available_algorithms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Algorithms for training or prediction\n",
      "\n",
      "    This function simply returns a dict of known\n",
      "    algorithms strings and their corresponding estimator function.\n",
      "\n",
      "    It exists to allow for a description of the mapping for\n",
      "    each of the valid strings as a docstring\n",
      "\n",
      "    The valid algorithm names, and the function they map to, are:\n",
      "\n",
      "    ============     ====================================\n",
      "    Algorithm        Function\n",
      "    ============     ====================================\n",
      "    linearSVC        sklearn.svm.LinearSVC\n",
      "    ============     ====================================\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(available_algorithms.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're in a position where the `make train` script can run using `linearSVC`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that `make train` takes a `models/model_list.json` as input. Let's make one.\n",
    "```\n",
    "## train / fit / build models\n",
    "train: models/model_list.json\n",
    "\t$(PYTHON_INTERPRETER) -m src.models.train_model model_list.json\n",
    "```\n",
    "\n",
    "A `model_list.json` is a list of dicts, where each dict specifices a combination of:\n",
    "* `dataset`: A valid dataset name from `available_datasets`\n",
    "* `dataset_params`: A dictionary of parameters that can be passed to `load_dataset()` with the specified `dataset`\n",
    "* `algorithm`: A valid dataset name from `available_algorithms`\n",
    "* `algorithm_params`: A dictionary of parameters to use when running the specified `algorithm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [\n",
    "    {\n",
    "        'dataset': 'lvq-pak',\n",
    "        'dataset_params': {},\n",
    "        'algorithm': 'linearSVC',\n",
    "        'algorithm_params': {'random_state': 42, 'max_iter': 200000},\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import model_path\n",
    "from src.utils import save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(model_path / 'model_list.json', model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"algorithm\": \"linearSVC\",\r\n",
      "    \"algorithm_params\": {\r\n",
      "      \"max_iter\": 200000,\r\n",
      "      \"random_state\": 42\r\n",
      "    },\r\n",
      "    \"dataset\": \"lvq-pak\",\r\n",
      "    \"dataset_params\": {}\r\n",
      "  }\r\n",
      "]"
     ]
    }
   ],
   "source": [
    "!cat ../models/model_list.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running `make train` will train `LinearSVC` on `lvq-pak` with the specified parameters.\n",
    "\n",
    "The output will be:\n",
    "* A trained model in `models/trained_models`\n",
    "* A json file `models/trained_models.json` that keeps track of the models that we've trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3 -m src.models.train_model model_list.json\n",
      "/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "2018-10-10 19:04:43,569 - train_model - INFO - Building models from model_list.json\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ava00125/src/devel/bus_number/src/models/train_model.py\", line 112, in <module>\n",
      "    main()\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 764, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 717, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 956, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/opt/software/anaconda3/envs/bus_number/lib/python3.7/site-packages/click/core.py\", line 555, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/ava00125/src/devel/bus_number/src/models/train_model.py\", line 71, in main\n",
      "    assert ds_name in dataset_list, f'Unknown Dataset: {ds_name}'\n",
      "AssertionError: Unknown Dataset: lvq-pak\n",
      "make: *** [train] Error 1\n"
     ]
    }
   ],
   "source": [
    "!cd .. && make train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any algorithm will work that: \n",
    "* is a subclass of the sklearn `BaseEstimator` class (needed for setting and getting params)\n",
    "* has a `fit` method (needed for `make train`)\n",
    "* has either a `predict` method (supervised) or a `transform` method (unsupervised) (needed for `make predict`)\n",
    "\n",
    "In particular, you can use an sklearn pipeline, or an sklearn meta estimator like GridSearchCV as an algorithm. \n",
    "\n",
    "If you algorithm of choice is **not** a `BaseEstimator` with the appropriate API, it is fairly easy to wrap it to be used in this way. While we won't have time to cover an example of this during the in-person part of this tutorial, the EDA Text Embedding (advanced usage tutorial) has an example of how to do this with gensim's FastText model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-84-13c602ec17af>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-84-13c602ec17af>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from sklearn.model_selection.GridSearchCV\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bus_number]",
   "language": "python",
   "name": "conda-env-bus_number-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
