{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Dataset\n",
    "from src import workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We’re gonna (data) science the *@#! out of this\n",
    "\n",
    "Now that we're getting good at automating the `Dataset` generation process, let's acutally **use** our data!\n",
    "\n",
    "## Bjørn's Problem: Supervised Learning\n",
    "\n",
    "Bjørn employs a large number of Finnish line cooks. He can’t understand a word they say.\n",
    "\n",
    "Bjørn needs a trained model to do real-time translation from Finnish to Swedish.\n",
    "\n",
    "Bjørn has decided to start with the Finnish phoneme dataset shipped with a project called lvq-pak. His objective is to train three different models, and choose the one with the best overall accuracy score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "In a previous notebook, we created training and test versions of the lvq-pak `Dataset` object. Let's reload these and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**: the data consists of 20-dimensional MFCC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.load('lvq-pak_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target labels are numerical. If for some reason you were interested in phoneme labels themselves, this map is stored in the Dataset metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train.LABEL_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the test set as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = Dataset.load('lvq-pak_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick look at the license verifies that, while we are free to use this data for experimentation, we can't turn around and ship a commercial Finnish to Swedish translator. That's okay. This is for Bjørn's kitchen only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds_train.LICENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a model (the old-fashioned way)\n",
    "We will walk through one example of building a model by hand. Later, we will convert this process to a reproducible data science workflow. \n",
    "\n",
    "Let's add the **Linear Support Vector Classifier** from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train.data, ds_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops. We had better increase the number of iterations until the model actually converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = LinearSVC(random_state=42, max_iter=200000)\n",
    "model.fit(ds_train.data, ds_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model to predict phoneme classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc_prediction = model.predict(ds_test.data);\n",
    "lsvc_prediction[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess the quality of the prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(ds_test.data, ds_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Score\" seems a little opaque. What kind of score is being used here? Turns out it's an **accuracy score**. Here it is a little more explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "help(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(ds_test.target, lsvc_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's automate this process, and make it reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train Models (`make train`)\n",
    "In this step, we use the processed datasets we created in *Step 2* (`make data`) to train and save models. For this workflow, a **Model** is an object that conforms to the scikit-learn `BaseEstimator` API.\n",
    "\n",
    "<img alt=\"The `make train` process\" src=\"../references/workflow/make-train.png\" width=500 />\n",
    "\n",
    "\n",
    "## Add our algorithm to `available_algorithms()`\n",
    "\n",
    "How do we make an algorithm available for use with our reprodible data science workflow? We give it a name (a text string), and map this string to the function we wish to call. We will use this general technique throughout this flow to make various algorithms, datasets, models, and analyses usable by our workflow process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add an algorithm to this list, we add a key:value pair to the dict `_ALGORITHMS` in `src/models/algorithms.py`.\n",
    "\n",
    "For example, add\n",
    "```\n",
    "'linearSVC': LinearSVC()\n",
    "```\n",
    "to the `_ALGORITHMS` dict, and add\n",
    "```\n",
    "from sklearn.svm import LinearSVC\n",
    "```\n",
    "to the top of the file.\n",
    "\n",
    "Also, add `linearSVC` to the docstring of `available_algorithms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(workflow.available_algorithms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add **model generation instructions** to our reproducible data science workflow. In this case, apply the `linearSVC` model to the `lvq-pak_train` dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_model(dataset_name='lvq-pak_train',\n",
    "                   algorithm_name=\"linearSVC\",\n",
    "                   algorithm_params={'random_state': 42, 'max_iter': 200000})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the complete list of model/dataset combinations using `get_model_list()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_model_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually train this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.build_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or alternately, from the Makefile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .. && make train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this process is a **trained model**. We currently record this in two places:\n",
    "* A trained model in `models/trained_models`\n",
    "* A json file on disk (`models/trained_models.json`).  \n",
    "\n",
    "Of course, we also make this information available via a workflow command: `available_models()`. Notice the clever naming scheme for the model produced by applying `linearSVC` to `lvq-pak_train`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: Under the Hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you take a peek into the `Makefile`, you'll notice that `make train` takes a `models/model_list.json` as input.\n",
    "```\n",
    "## train / fit / build models\n",
    "train: models/model_list.json\n",
    "\t$(PYTHON_INTERPRETER) -m src.models.train_model model_list.json\n",
    "```\n",
    "\n",
    "Under the hood, a `model_list.json` is a list of dicts, where each dict specifices a combination of:\n",
    "* `dataset_name`: A valid dataset name from `available_datasets()`\n",
    "* `algorithm_name`: A valid dataset name from `available_algorithms()`\n",
    "* `algorithm_params`: A dictionary of parameters to use when running the specified algorithm\n",
    "* `run_number`: (optional, default 1) A unique integer used to distinguish between different builds with otherwise identical parameters\n",
    "\n",
    "Throughout this reproducible data science workflow, we are constantly creating and storing information in json files on disk.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../models/model_list.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't necessarily need to know any of this, but sometimes it's nice to know what's going on under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What exactly is a trained model in our reproducible workflow?\n",
    "Let's take a look at the output from `make train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import trained_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the trained model\n",
    "from src.models.train import load_model\n",
    "\n",
    "tm, tm_metadata = load_model(model_name='linearSVC_lvq-pak_train_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, this is function that conforms to the sklearn `BaseEstimator` API. In addition to the trained model, we also returned some useful metadata, which includes the hashes of the input data, the hash of the generated model, and everything we need to know to train the model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to check, we can verify that the stored dataset called `lvq-pak_train` was the same one used to train this model: (**data provenance** in action!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load('lvq-pak_train')\n",
    "ds.DATA_HASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Aside: sklearn Estimator API\n",
    "To implement the notion of a model, we borrow a basic data type from scikit-learn: the **BaseEstimator**. To use an algorithm as a model, we must build it into a class which:\n",
    "* is a subclass of the sklearn `BaseEstimator` class (or implements `get_params`, `set_params`)\n",
    "* has a `fit` method (needed for `make train`)\n",
    "* has either a `predict` method (if it's a **supervised learning** problem) or a `transform` method (**unsupervised learning** problem) (needed for `make predict`)\n",
    "\n",
    "We will see how things work in the unsupervised case in the next workbook. \n",
    "\n",
    "One of the advantages of using the sklearn **Estimator** API is that a model can consist of any combination of \"algorithms\" as long as that combination is a `BaseEstimator` implementing above methods. For example, you can use an sklearn `Pipeline`, or an sklearn meta-estimator like `GridSearchCV` to implement a model. \n",
    "\n",
    "If your algorithm of choice is **not yet** a `BaseEstimator` with the appropriate API, it is fairly easy to wrap it to be used in this way. While we won't have time to cover an example of doing this during the in-person part of this tutorial, we'll give an example of a custom estimator later in this notebook using `GridSearchCV`. Furthermore, the Text Embedding (advanced usage tutorial notebook) has an example of implementing gensim's FastText algorithm as an Estimator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: `make predict`\n",
    "\n",
    "In the **Predict/Transform** step, we flow data through our trained models to obtain **new Datasets** - either predictions, or transformations, depending whether we are using supervised or unsupervised-style algorithms. \n",
    "\n",
    "<img alt=\"The `make predict` process\" src=\"../references/workflow/make-predict.png\" width=500/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Phonemes\n",
    "Bjørn is doing supervised learning, (and he did a train/test split on the data before we started), so let's use the test set here to do the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_prediction(dataset_name='lvq-pak_test',\n",
    "                        model_name='linearSVC_lvq-pak_train_1',\n",
    "                        is_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_prediction_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.run_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the same as\n",
    "!cd .. && make predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yuck. We didn't specify an output dataset name, so our workflow just inferred one that makes sense (though it is a bit of a mouthful). Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_prediction_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = workflow.pop_prediction()\n",
    "prediction['output_dataset'] = 'lvq-test-svc'\n",
    "workflow.add_prediction(**prediction)\n",
    "workflow.get_prediction_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.run_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.available_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two predictions. We'll see here that they are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Prediction?\n",
    "\n",
    "Under the hood, a Prediction is just a `Dataset` with an added `experiment` metadata header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.paths import model_output_path\n",
    "from src.utils import list_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir(model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ds = Dataset.load('lvq-test-svc', data_path=model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ds.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ds.metadata['experiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have saved all sorts of useful information, such as the hashes of the data that went in, and the start time/diration of the prediction itself. Most importantly, the prediction we got via this process was exactly the same as the one we did manually, before converting our process to a reproducible workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.load('lvq-pak_test')\n",
    "ds.DATA_HASH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, check that our prediction matches what we got **before** we turned this into an automated reproducible workflow:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(predict_ds.data == lsvc_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An Aside: \"Randomness\" and `random_state`\n",
    "Randomness is often a key feature of machine learning algorithms, but for reproducible data science, it is death. It's essential, when building reproducible data science flows, that our randomness is controlled by a deterministic `random_state` (or random_seed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, model_meta = load_model('linearSVC_lvq-pak_train_1')\n",
    "model_meta['algorithm_params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Always** pass in a `random_state`. If we want to run our algorithm multiple times with different random states, we can even use `GridSearchCV` where the only parameter that we're varying over is the `random_state`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: `make train`, `make predict`\n",
    "That felt like a lot of exposition. In fact, here's what we ended up doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add `linearSCV` to the algorithm list in `src/models/algorithms.py`\n",
    "\n",
    "# train a model called \"linearSVC_lvq-pak_train_1\"\n",
    "workflow.add_model(dataset_name='lvq-pak_train',\n",
    "                   algorithm_name=\"linearSVC\",\n",
    "                   algorithm_params={'random_state': 42, 'max_iter': 200000})\n",
    "# \n",
    "workflow.add_prediction(dataset_name='lvq-pak_test',\n",
    "                        model_name='linearSVC_lvq-pak_train_1', \n",
    "                        is_supervised=True, output_dataset='lvq-tets-svc')\n",
    "\n",
    "workflow.build_models()  # or `make train`\n",
    "workflow.run_predictions() # or `make predict`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bus_number]",
   "language": "python",
   "name": "conda-env-bus_number-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
